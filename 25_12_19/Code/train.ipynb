{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9760392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "# Import from refactored modules\n",
    "from sample import MNISTSampler, IsotropicGaussian\n",
    "from scheduler import LinearAlpha, LinearBeta\n",
    "from path import GaussianConditionalProbabilityPath, CFGVectorFieldODE\n",
    "from sde import EulerSimulator\n",
    "from Unet import MNISTUNet\n",
    "from trainer import CFGTrainer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a4738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize probability path\n",
    "path = GaussianConditionalProbabilityPath(\n",
    "    p_data = MNISTSampler(),\n",
    "    p_simple_shape = [1, 32, 32],\n",
    "    alpha = LinearAlpha(),\n",
    "    beta = LinearBeta()\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4fa13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "unet = MNISTUNet(\n",
    "    channels = [32, 64, 128],\n",
    "    num_residual_layers = 2,\n",
    "    t_embed_dim = 40,\n",
    "    y_embed_dim = 40,\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = CFGTrainer(path=path, model=unet, eta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bdcacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train!\n",
    "trainer.train(num_epochs=500, device=device, lr=1e-3, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32c80ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with these!\n",
    "samples_per_class = 10\n",
    "num_timesteps = 100\n",
    "guidance_scales = [1.0, 3.0, 5.0]\n",
    "\n",
    "# Graph\n",
    "fig, axes = plt.subplots(1, len(guidance_scales), figsize=(10 * len(guidance_scales), 10))\n",
    "\n",
    "for idx, w in enumerate(guidance_scales):\n",
    "    # Setup ode and simulator\n",
    "    ode = CFGVectorFieldODE(unet, guidance_scale=w)\n",
    "    simulator = EulerSimulator(ode)\n",
    "\n",
    "    # Sample initial conditions\n",
    "    y = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=torch.int64).repeat_interleave(samples_per_class).to(device)\n",
    "    num_samples = y.shape[0]\n",
    "    x0, _ = path.p_simple.sample(num_samples)  # (num_samples, 1, 32, 32)\n",
    "\n",
    "    # Simulate\n",
    "    ts = torch.linspace(0, 1, num_timesteps).view(1, -1, 1, 1, 1).expand(num_samples, -1, 1, 1, 1).to(device)\n",
    "    x1 = simulator.simulate(x0, ts, y=y)\n",
    "\n",
    "    # Plot\n",
    "    grid = make_grid(x1, nrow=samples_per_class, normalize=True, value_range=(-1, 1))\n",
    "    axes[idx].imshow(grid.permute(1, 2, 0).cpu(), cmap=\"gray\")\n",
    "    axes[idx].axis(\"off\")\n",
    "    axes[idx].set_title(f\"Guidance: $w={w:.1f}$\", fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56440025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize samples from conditional probability path\n",
    "num_rows = 3\n",
    "num_cols = 3\n",
    "num_timesteps_vis = 5\n",
    "\n",
    "# Sample \n",
    "num_samples = num_rows * num_cols\n",
    "z, _ = path.p_data.sample(num_samples)\n",
    "z = z.view(-1, 1, 32, 32)\n",
    "\n",
    "# Setup plot\n",
    "fig, axes = plt.subplots(1, num_timesteps_vis, figsize=(6 * num_cols * num_timesteps_vis, 6 * num_rows))\n",
    "\n",
    "# Sample from conditional probability paths and graph\n",
    "ts = torch.linspace(0, 1, num_timesteps_vis).to(device)\n",
    "for tidx, t in enumerate(ts):\n",
    "    tt = t.view(1,1,1,1).expand(num_samples, 1, 1, 1)  # (num_samples, 1, 1, 1)\n",
    "    xt = path.sample_conditional_path(z, tt)  # (num_samples, 1, 32, 32)\n",
    "    grid = make_grid(xt, nrow=num_cols, normalize=True, value_range=(-1,1))\n",
    "    axes[tidx].imshow(grid.permute(1, 2, 0).cpu(), cmap=\"gray\")\n",
    "    axes[tidx].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e5cf53",
   "metadata": {},
   "source": [
    "# Using Diffusers UNet2DModel\n",
    "\n",
    "Below we demonstrate using the `diffusers` library's UNet2DModel wrapped for our framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b06709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the diffusers wrapper\n",
    "from Unet import DiffusersUNet2DWrapperLite, DiffusersUNet2DWrapper\n",
    "\n",
    "# Check if diffusers is available\n",
    "try:\n",
    "    from diffusers import UNet2DModel\n",
    "    print(\"✓ diffusers library is available\")\n",
    "except ImportError:\n",
    "    print(\"✗ diffusers not installed. Install with: pip install diffusers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b54b6",
   "metadata": {},
   "source": [
    "## Option 1: Lightweight Diffusers UNet (Pre-configured for MNIST 28x28)\n",
    "\n",
    "This uses a lightweight configuration optimized for MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58140c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sampler for 28x28 images (diffusers UNet expects 28x28, not 32x32)\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class MNISTSampler28(torch.nn.Module):\n",
    "    \"\"\"MNIST sampler for 28x28 images (for diffusers UNet)\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dataset = datasets.MNIST(\n",
    "            root='./data',\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "            ])\n",
    "        )\n",
    "        self.dummy = torch.nn.Buffer(torch.zeros(1))\n",
    "    \n",
    "    def sample(self, num_samples: int):\n",
    "        if num_samples > len(self.dataset):\n",
    "            raise ValueError(f\"num_samples exceeds dataset size\")\n",
    "        indices = torch.randperm(len(self.dataset))[:num_samples]\n",
    "        samples, labels = zip(*[self.dataset[i] for i in indices])\n",
    "        samples = torch.stack(samples).to(self.dummy.device)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64).to(self.dummy.device)\n",
    "        return samples, labels\n",
    "\n",
    "# Initialize probability path for 28x28 images\n",
    "path_diffusers = GaussianConditionalProbabilityPath(\n",
    "    p_data = MNISTSampler28(),\n",
    "    p_simple_shape = [1, 28, 28],\n",
    "    alpha = LinearAlpha(),\n",
    "    beta = LinearBeta()\n",
    ").to(device)\n",
    "\n",
    "print(\"✓ Created path for 28x28 images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea76e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lightweight diffusers UNet\n",
    "unet_diffusers_lite = DiffusersUNet2DWrapperLite(num_class_embeds=11)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer_diffusers_lite = CFGTrainer(path=path_diffusers, model=unet_diffusers_lite, eta=0.1)\n",
    "\n",
    "print(\"✓ Created lightweight diffusers UNet model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2fdb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the diffusers UNet!\n",
    "trainer_diffusers_lite.train(num_epochs=500, device=device, lr=1e-3, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91685eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample and visualize results from diffusers UNet\n",
    "samples_per_class = 10\n",
    "num_timesteps = 100\n",
    "guidance_scales = [1.0, 3.0, 5.0]\n",
    "\n",
    "# Graph\n",
    "fig, axes = plt.subplots(1, len(guidance_scales), figsize=(10 * len(guidance_scales), 10))\n",
    "\n",
    "for idx, w in enumerate(guidance_scales):\n",
    "    # Setup ode and simulator\n",
    "    ode = CFGVectorFieldODE(unet_diffusers_lite, guidance_scale=w)\n",
    "    simulator = EulerSimulator(ode)\n",
    "\n",
    "    # Sample initial conditions\n",
    "    y = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int64).repeat_interleave(samples_per_class).to(device)\n",
    "    num_samples = y.shape[0]\n",
    "    x0, _ = path_diffusers.p_simple.sample(num_samples)  # (num_samples, 1, 28, 28)\n",
    "\n",
    "    # Simulate\n",
    "    ts = torch.linspace(0, 1, num_timesteps).view(1, -1, 1, 1, 1).expand(num_samples, -1, 1, 1, 1).to(device)\n",
    "    x1 = simulator.simulate(x0, ts, y=y)\n",
    "\n",
    "    # Plot\n",
    "    grid = make_grid(x1, nrow=samples_per_class, normalize=True, value_range=(-1, 1))\n",
    "    axes[idx].imshow(grid.permute(1, 2, 0).cpu(), cmap=\"gray\")\n",
    "    axes[idx].axis(\"off\")\n",
    "    axes[idx].set_title(f\"Diffusers UNet - Guidance: $w={w:.1f}$\", fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c7214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model sizes\n",
    "from trainer import model_size_b\n",
    "\n",
    "MiB = 1024 ** 2\n",
    "\n",
    "print(\"Model Size Comparison:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Original MNISTUNet:           {model_size_b(unet) / MiB:.2f} MiB\")\n",
    "print(f\"Diffusers UNet (Lite):        {model_size_b(unet_diffusers_lite) / MiB:.2f} MiB\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Count parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\nParameter Count:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Original MNISTUNet:           {count_parameters(unet):,}\")\n",
    "print(f\"Diffusers UNet (Lite):        {count_parameters(unet_diffusers_lite):,}\")\n",
    "print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DGM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
